{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "if LOCAL:\n",
    "    import sys\n",
    "    sys.path.append('./utils/*.*')\n",
    "    from utils.preprocess import *\n",
    "    market_train_df = pd.read_csv('./data/marketdata_sample.csv')\n",
    "    news_train = pd.read_csv('./data/news_sample.csv')\n",
    "    market_train_df['time'] = pd.to_datetime(market_train_df.time)\n",
    "    news_train['time'] = pd.to_datetime(news_train.time)\n",
    "else:\n",
    "    from kaggle.competitions import twosigmanews\n",
    "    from utils import *\n",
    "    env = twosigmanews.make_env()\n",
    "    market_train_df, news_train = env.get_training_data()\n",
    "    market_train_df['time'] = pd.to_datetime(market_train_df.time)\n",
    "    news_train['time'] = pd.to_datetime(news_train.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time                        datetime64[ns]\n",
       "assetCode                           object\n",
       "assetName                           object\n",
       "universe                           float64\n",
       "volume                             float64\n",
       "close                              float64\n",
       "open                               float64\n",
       "returnsClosePrevRaw1               float64\n",
       "returnsOpenPrevRaw1                float64\n",
       "returnsClosePrevMktres1            float64\n",
       "returnsOpenPrevMktres1             float64\n",
       "returnsClosePrevRaw10              float64\n",
       "returnsOpenPrevRaw10               float64\n",
       "returnsClosePrevMktres10           float64\n",
       "returnsOpenPrevMktres10            float64\n",
       "returnsOpenNextMktres10            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "start = pd.to_datetime('2009-01-01')\n",
    "market_train = market_train_df.loc[market_train_df['time']>= start].reset_index(drop=True)\n",
    "news_train = news_train.loc[news_train['time'] >= start].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assetCode</th>\n",
       "      <th>time</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>provider</th>\n",
       "      <th>bodySize</th>\n",
       "      <th>companyCount</th>\n",
       "      <th>headlineTag</th>\n",
       "      <th>marketCommentary</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [assetCode, time, sourceId, urgency, takeSequence, provider, bodySize, companyCount, headlineTag, marketCommentary, sentenceCount, wordCount, firstMentionSentence, relevance, sentimentClass, sentimentNegative, sentimentNeutral, sentimentPositive, sentimentWordCount, noveltyCount12H, noveltyCount24H, noveltyCount3D, noveltyCount5D, noveltyCount7D, volumeCounts12H, volumeCounts24H, volumeCounts3D, volumeCounts5D, volumeCounts7D]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train = preprocess_news(news_train)\n",
    "index_df = unstack_asset_codes(news_train)\n",
    "index_df.head()\n",
    "news_unstack = merge_news_on_index(news_train, index_df)\n",
    "del news_train, index_df\n",
    "gc.collect()\n",
    "news_unstack.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assetCode</th>\n",
       "      <th>date</th>\n",
       "      <th>sourceId_mean</th>\n",
       "      <th>urgency_mean</th>\n",
       "      <th>takeSequence_mean</th>\n",
       "      <th>provider_mean</th>\n",
       "      <th>bodySize_mean</th>\n",
       "      <th>companyCount_mean</th>\n",
       "      <th>headlineTag_mean</th>\n",
       "      <th>marketCommentary_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H_mean</th>\n",
       "      <th>noveltyCount24H_mean</th>\n",
       "      <th>noveltyCount3D_mean</th>\n",
       "      <th>noveltyCount5D_mean</th>\n",
       "      <th>noveltyCount7D_mean</th>\n",
       "      <th>volumeCounts12H_mean</th>\n",
       "      <th>volumeCounts24H_mean</th>\n",
       "      <th>volumeCounts3D_mean</th>\n",
       "      <th>volumeCounts5D_mean</th>\n",
       "      <th>volumeCounts7D_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [assetCode, date, sourceId_mean, urgency_mean, takeSequence_mean, provider_mean, bodySize_mean, companyCount_mean, headlineTag_mean, marketCommentary_mean, sentenceCount_mean, wordCount_mean, firstMentionSentence_mean, relevance_mean, sentimentClass_mean, sentimentNegative_mean, sentimentNeutral_mean, sentimentPositive_mean, sentimentWordCount_mean, noveltyCount12H_mean, noveltyCount24H_mean, noveltyCount3D_mean, noveltyCount5D_mean, noveltyCount7D_mean, volumeCounts12H_mean, volumeCounts24H_mean, volumeCounts3D_mean, volumeCounts5D_mean, volumeCounts7D_mean]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_agg = group_news(news_unstack)\n",
    "del news_unstack; gc.collect()\n",
    "news_agg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergei/Kaggle/2Sigma/utils/preprocess.py:86: FutureWarning: 'assetCode' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  df[std_column] = df.groupby('assetCode')[col].apply(lambda x: x.rolling(window).std())\n",
      "/home/sergei/Kaggle/2Sigma/utils/preprocess.py:84: FutureWarning: 'assetCode' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  df[ma_column] = df.groupby('assetCode')[col].apply(lambda x: x.rolling(window).mean())\n"
     ]
    }
   ],
   "source": [
    "market_train = process_date(market_train)\n",
    "market_train = process_ma(market_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergei/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: 'assetCode' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and float64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-eecac794315e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_agg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assetCode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmarket_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   6387\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6388\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6389\u001b[0;31m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[1;32m   6390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             elif (not is_numeric_dtype(lk)\n\u001b[1;32m    985\u001b[0m                     and (is_numeric_dtype(rk) and not is_bool_dtype(rk))):\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and float64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "df = market_train.merge(news_agg, how='left', on=['assetCode', 'date'])\n",
    "del market_train, news_agg\n",
    "gc.collect()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "date = df.date\n",
    "num_target = df.returnsOpenNextMktres10.astype('float32')\n",
    "bin_target = (df.returnsOpenNextMktres10 >= 0).astype('int8')\n",
    "universe = df.universe.astype('int8')\n",
    "# Drop columns that are not features\n",
    "df.drop(['returnsOpenNextMktres10', 'date', 'universe', 'assetCode', 'assetName', 'time'], \n",
    "        axis=1, inplace=True)\n",
    "df = df.astype('float32')  # Set all remaining columns to float32 datatype\n",
    "gc.collect()\n",
    "\n",
    "train_index, test_index = train_test_split(df.index.values, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.02, 0.01],\n",
    "    'num_leaves': [25, 38, 63],\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'min_child_samples': [5, 10, 20, 40, 100],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'reg_alpha': [0.1, 0.2, 0.4, 0.6, 0.8],\n",
    "    'reg_lambda': [0.1, 0.2, 0.4, 0.6, 0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "best_eval_score = 0\n",
    "for i in range(50):\n",
    "    params = {k: np.random.choice(v) for k, v in param_grid.items()}\n",
    "    score = evaluate_model(df, bin_target, train_index, test_index, params)\n",
    "    if score < best_eval_score or best_eval_score == 0:\n",
    "        best_eval_score = score\n",
    "        best_params = params\n",
    "    print(best_eval_score)\n",
    "print(\"Best evaluation logloss\", best_eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Train model with full data\n",
    "clf = LGBMClassifier(**best_params)\n",
    "clf.fit(df, bin_target)\n",
    "\n",
    "test_df_columns = ['time', 'assetCode', 'assetName', 'volume', 'close', 'open',\n",
    "                   'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n",
    "                   'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n",
    "                   'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n",
    "                   'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n",
    "base_df = market_train_df[market_train_df['time'] >= '2016-10-01']\n",
    "base_df = base_df[test_df_columns]\n",
    "base_df['id'] = -1\n",
    "base_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "def write_submission(model, env):\n",
    "    days = env.get_prediction_days()\n",
    "    day_id = 0\n",
    "    market_obs_df_append = None\n",
    "    for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "        news_obs_df = preprocess_news(news_obs_df)\n",
    "        # Unstack news\n",
    "        index_df = unstack_asset_codes(news_obs_df)\n",
    "        news_unstack = merge_news_on_index(news_obs_df, index_df)\n",
    "        # Group and and get aggregations (mean)\n",
    "        news_obs_agg = group_news(news_unstack)\n",
    "\n",
    "        market_obs_df['id'] = day_id\n",
    "        if market_obs_df_append is None:\n",
    "            market_obs_df_append = base_df\n",
    "            \n",
    "        market_obs_df_append = pd.concat([market_obs_df_append,market_obs_df],\n",
    "                                         ignore_index=True,\n",
    "                                         sort=False)\n",
    "        \n",
    "        market_obs_process = process_date(market_obs_df_append)\n",
    "        market_obs_process = process_ma(market_obs_process)\n",
    "        market_obs_df = market_obs_process[market_obs_process['id']==day_id]\n",
    "        # Join market and news frames\n",
    "        obs_df = market_obs_df.merge(news_obs_agg, how='left', on=['assetCode', 'date'])\n",
    "        del market_obs_df, news_obs_agg, news_obs_df, news_unstack, index_df\n",
    "        gc.collect()\n",
    "        obs_df = obs_df[obs_df.assetCode.isin(predictions_template_df.assetCode)]\n",
    "        # Drop cols that are not features\n",
    "        feats = [c for c in obs_df.columns if c not in ['date', 'assetCode', 'assetName', 'time', 'id']]\n",
    "\n",
    "        preds = model.predict_proba(obs_df[feats])[:, 1] * 2 - 1\n",
    "        sub = pd.DataFrame({'assetCode': obs_df['assetCode'], 'confidence': preds})\n",
    "        predictions_template_df = predictions_template_df.merge(sub, how='left').drop(\n",
    "            'confidenceValue', axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "        \n",
    "        env.predict(predictions_template_df)\n",
    "        if day_id == 59:\n",
    "            market_obs_df_append.drop(\n",
    "                market_obs_df_append.index[market_obs_df_append['id']==-1],\n",
    "                inplace=True)\n",
    "        elif day_id >= 60:\n",
    "            market_obs_df_append.drop(\n",
    "                market_obs_df_append.index[market_obs_df_append['id']==day_id-60],\n",
    "                inplace=True)\n",
    "        day_id += 1\n",
    "        del obs_df, predictions_template_df, preds, sub\n",
    "        gc.collect()\n",
    "    env.write_submission_file()\n",
    "    print('day_count',day_id)\n",
    "\n",
    "write_submission(clf, env)\n",
    "\n",
    "feat_importance = pd.DataFrame()\n",
    "feat_importance[\"feature\"] = df.columns\n",
    "feat_importance[\"gain\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "feat_importance.sort_values(by='gain', ascending=False, inplace=True)\n",
    "plt.figure(figsize=(8,10))\n",
    "ax = sns.barplot(y=\"feature\", x=\"gain\", data=feat_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
